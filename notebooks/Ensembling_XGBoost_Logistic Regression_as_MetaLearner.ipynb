{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8ec376",
   "metadata": {},
   "source": [
    "# Ensembling XGBoost models with Logistic Regression as Meta-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path, image_folder, image_id_column, class_column, target_classes):\n",
    "    \"\"\"\n",
    "    Load data from CSV file and images from the specified folder.\n",
    "\n",
    "    Args:\n",
    "    - csv_path (str): Path to the CSV file containing data.\n",
    "    - image_folder (str): Path to the folder containing images.\n",
    "    - image_id_column (str): Name of the column containing image IDs.\n",
    "    - class_column (str): Name of the column containing class labels.\n",
    "    - target_classes (list): List of target class labels.\n",
    "\n",
    "    Returns:\n",
    "    - data (DataFrame): Loaded data from CSV.\n",
    "    - images (ndarray): Loaded images as numpy array.\n",
    "    - labels (ndarray): Encoded class labels.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(csv_path)\n",
    "    images = []\n",
    "    for image_id in data[image_id_column]:\n",
    "        img_path = os.path.join(image_folder, f\"{image_id}.jpg\")\n",
    "        img = load_img(img_path, target_size=image_size)\n",
    "        img_array = img_to_array(img).flatten()\n",
    "        images.append(img_array)\n",
    "    images = np.array(images)\n",
    "    label_encoder = LabelEncoder()\n",
    "    data[class_column] = label_encoder.fit_transform(data[class_column])\n",
    "    labels = data[class_column]\n",
    "    return data, images, labels\n",
    "\n",
    "def train_xgboost_model(X_train, y_train, X_val, y_val, **kwargs):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model.\n",
    "\n",
    "    Args:\n",
    "    - X_train (ndarray): Training features.\n",
    "    - y_train (ndarray): Training labels.\n",
    "    - X_val (ndarray): Validation features.\n",
    "    - y_val (ndarray): Validation labels.\n",
    "    - **kwargs: Additional keyword arguments for XGBoost training.\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained XGBoost model.\n",
    "    \"\"\"\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    model = xgb.XGBClassifier(**kwargs)\n",
    "    model.fit(X_train_resampled, y_train_resampled, \n",
    "              eval_set=[(X_train_resampled, y_train_resampled), (X_val, y_val)], \n",
    "              eval_metric=[\"merror\", \"mlogloss\"], \n",
    "              early_stopping_rounds=10, \n",
    "              verbose=True)\n",
    "    return model\n",
    "\n",
    "def extract_image_features(data, image_folder, image_id_column, cnn_model):\n",
    "    \"\"\"\n",
    "    Extract image features using a pre-trained CNN model.\n",
    "\n",
    "    Args:\n",
    "    - data (DataFrame): Data containing image IDs.\n",
    "    - image_folder (str): Path to the folder containing images.\n",
    "    - image_id_column (str): Name of the column containing image IDs.\n",
    "    - cnn_model: Pre-trained CNN model.\n",
    "\n",
    "    Returns:\n",
    "    - extracted_features (ndarray): Extracted image features.\n",
    "    - image_ids (ndarray): Image IDs.\n",
    "    \"\"\"\n",
    "    extracted_features = []\n",
    "    image_ids = []\n",
    "    for index, row in data.iterrows():\n",
    "        image_id = row[image_id_column]\n",
    "        image_path = os.path.join(image_folder, f\"{image_id}.jpg\")\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image_array = img_to_array(image)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        image_array = image_array / 255.0\n",
    "        features = cnn_model.predict(image_array)\n",
    "        extracted_features.append(features.flatten())\n",
    "        image_ids.append(image_id)\n",
    "    extracted_features = np.array(extracted_features)\n",
    "    image_ids = np.array(image_ids)\n",
    "    return extracted_features, image_ids\n",
    "\n",
    "def preprocess_data(csv_path, image_folder, image_id_column, class_column, target_classes):\n",
    "    \"\"\"\n",
    "    Preprocess data by loading, encoding labels, and extracting image features.\n",
    "\n",
    "    Args:\n",
    "    - csv_path (str): Path to the CSV file containing data.\n",
    "    - image_folder (str): Path to the folder containing images.\n",
    "    - image_id_column (str): Name of the column containing image IDs.\n",
    "    - class_column (str): Name of the column containing class labels.\n",
    "    - target_classes (list): List of target class labels.\n",
    "\n",
    "    Returns:\n",
    "    - data (DataFrame): Preprocessed data from CSV.\n",
    "    - images (ndarray): Loaded and preprocessed images.\n",
    "    - labels (ndarray): Encoded class labels.\n",
    "    - well_log_data (DataFrame): Processed data excluding image-related columns.\n",
    "    \"\"\"\n",
    "    data, images, labels = load_data(csv_path, image_folder, image_id_column, class_column, target_classes)\n",
    "    well_log_data = data.drop(columns=['IMAGE_ID', 'DEPTH_WMSF (m)'])\n",
    "    return data, images, labels, well_log_data\n",
    "\n",
    "def load_cnn_model(input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Load a pre-trained CNN model (VGG19).\n",
    "\n",
    "    Args:\n",
    "    - input_shape (tuple): Input shape of the model.\n",
    "\n",
    "    Returns:\n",
    "    - cnn_model: Pre-trained CNN model.\n",
    "    \"\"\"\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    cnn_model = Model(inputs=base_model.input, outputs=x)\n",
    "    return cnn_model\n",
    "\n",
    "def train_and_evaluate_image_model(data, images, labels, cnn_model):\n",
    "    \"\"\"\n",
    "    Train and evaluate the image model.\n",
    "\n",
    "    Args:\n",
    "    - data (DataFrame): Data containing image IDs.\n",
    "    - images (ndarray): Loaded and preprocessed images.\n",
    "    - labels (ndarray): Encoded class labels.\n",
    "    - cnn_model: Pre-trained CNN model.\n",
    "    \"\"\"\n",
    "    X_train_img, X_test_img, y_train_img, y_test_img = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    X_train_img, X_val_img, y_train_img, y_val_img = train_test_split(X_train_img, y_train_img, test_size=0.25, random_state=42)\n",
    "    extracted_features, _ = extract_image_features(data, image_folder, image_id_column, cnn_model)\n",
    "    image_model = train_xgboost_model(X_train_img, y_train_img, X_val_img, y_val_img)\n",
    "    plot_training_curves(image_model.evals_result())\n",
    "    evaluate_model(image_model, X_test_img, y_test_img)\n",
    "\n",
    "def train_and_evaluate_tabular_model(well_log_data, labels):\n",
    "    \"\"\"\n",
    "    Train and evaluate the tabular model.\n",
    "\n",
    "    Args:\n",
    "    - well_log_data (DataFrame): Processed data excluding image-related columns.\n",
    "    - labels (ndarray): Encoded class labels.\n",
    "    \"\"\"\n",
    "    X_train_tabular, X_test_tabular, y_train_tabular, y_test_tabular = train_test_split(well_log_data, labels, test_size=0.2, random_state=42)\n",
    "    X_train_tabular, X_val_tabular, y_train_tabular, y_val_tabular = train_test_split(X_train_tabular, y_train_tabular, test_size=0.25, random_state=42)\n",
    "    tabular_model = train_xgboost_model(X_train_tabular, y_train_tabular, X_val_tabular, y_val_tabular)\n",
    "    plot_training_curves(tabular_model.evals_result())\n",
    "    evaluate_model(tabular_model, X_test_tabular, y_test_tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a8140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_ensemble_model(data, images, well_log_data, labels, cnn_model, **kwargs):\n",
    "    \"\"\"\n",
    "    Train and evaluate the ensemble model.\n",
    "\n",
    "    Args:\n",
    "    - data (DataFrame): Data containing image IDs.\n",
    "    - images (ndarray): Loaded and preprocessed images.\n",
    "    - well_log_data (DataFrame): Processed data excluding image-related columns.\n",
    "    - labels (ndarray): Encoded class labels.\n",
    "    - cnn_model: Pre-trained CNN model.\n",
    "    - **kwargs: Additional keyword arguments for XGBoost training and stacking classifier.\n",
    "\n",
    "    Returns:\n",
    "    - stacking_model: Trained stacking classifier.\n",
    "    \"\"\"\n",
    "    X_train_img, X_test_img, y_train_img, y_test_img = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    X_train_img, X_val_img, y_train_img, y_val_img = train_test_split(X_train_img, y_train_img, test_size=0.25, random_state=42)\n",
    "    \n",
    "    extracted_features, _ = extract_image_features(data, image_folder, image_id_column, cnn_model)\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_img_resampled, y_train_img_resampled = ros.fit_resample(X_train_img, y_train_img)\n",
    "    X_train_tabular_resampled, y_train_tabular_resampled = ros.fit_resample(well_log_data, labels)\n",
    "    \n",
    "    image_model = train_xgboost_model(X_train_img_resampled, y_train_img_resampled, X_val_img, y_val_img, **kwargs)\n",
    "    tabular_model = train_xgboost_model(X_train_tabular_resampled, y_train_tabular_resampled, X_val_tabular, y_val_tabular, **kwargs)\n",
    "    \n",
    "    y_pred_img_val = cross_val_predict(image_model, X_val_img, y_val_img, **kwargs)\n",
    "    y_pred_tabular_val = cross_val_predict(tabular_model, X_val_tabular, y_val_tabular, **kwargs)\n",
    "\n",
    "    final_estimator = LogisticRegression()\n",
    "    estimators = [('image', image_model), ('tabular', tabular_model)]\n",
    "    stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator)\n",
    "    stacking_model.fit(np.column_stack((y_pred_img_val, y_pred_tabular_val)), y_val_tabular)\n",
    "\n",
    "    return stacking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and columns\n",
    "csv_path = \"/path/to/csv/file.csv\"\n",
    "image_folder = \"/path/to/image/folder\"\n",
    "image_id_column = \"IMAGE_ID\" \n",
    "class_column = \"ROCK_CLASS\"\n",
    "target_classes = ['Wackestone', 'Packstone', 'Grainstone', 'Floatstone', 'Rudstone']\n",
    "\n",
    "# Define image size\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Preprocess data\n",
    "data, images, labels, well_log_data = preprocess_data(csv_path, image_folder, image_id_column, class_column, target_classes)\n",
    "\n",
    "# Load CNN model\n",
    "cnn_model = load_cnn_model()\n",
    "\n",
    "# Train and evaluate ensemble model\n",
    "stacking_model = train_and_evaluate_ensemble_model(data, images, well_log_data, labels, cnn_model, **{'cv': 5})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
